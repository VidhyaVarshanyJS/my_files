{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["3sFHxhQvAJmu","T4sFIYtKgx-H","4NtS81Dug62B"],"authorship_tag":"ABX9TyOmqCSmFQfMMa8FRiHb2XaN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d66eedb40eae418fa06c631194e35f35":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0446a2b38ec4d5ca3b98b0e6f68021a","IPY_MODEL_57fce6c42d954bf198e3652010a4ee17","IPY_MODEL_9ab1537fc6b24e1aaebfcf67815a5a39"],"layout":"IPY_MODEL_340d881dc42a4de684245dd761bc46d2"}},"b0446a2b38ec4d5ca3b98b0e6f68021a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52b8d1db561e44789108b9ed39c310db","placeholder":"​","style":"IPY_MODEL_2eaf3ac5d8ff423f9c416808006bd91f","value":"Map (num_proc=3): 100%"}},"57fce6c42d954bf198e3652010a4ee17":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fae11f64f19b4b29a010f66b39fffb09","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41c9922853cc48a893833f59fe4be898","value":100}},"9ab1537fc6b24e1aaebfcf67815a5a39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb0ddc83f6d34c878e7df8ac0987327e","placeholder":"​","style":"IPY_MODEL_c5bf48e8952642658fdbb71f3d1459d8","value":" 100/100 [09:40&lt;00:00,  6.94s/ examples]"}},"340d881dc42a4de684245dd761bc46d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52b8d1db561e44789108b9ed39c310db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eaf3ac5d8ff423f9c416808006bd91f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fae11f64f19b4b29a010f66b39fffb09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41c9922853cc48a893833f59fe4be898":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb0ddc83f6d34c878e7df8ac0987327e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5bf48e8952642658fdbb71f3d1459d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d72a19f2e4824ceb9b8a338761c26e8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7673cc7f6a614f7d9bdd22d918127e51","IPY_MODEL_640c9401a2b54ad2bd90c0638fd15f5d","IPY_MODEL_1693a163c26f4bfd986acbf96b86c527"],"layout":"IPY_MODEL_bc3860755fb848399ceeab6523f25628"}},"7673cc7f6a614f7d9bdd22d918127e51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0b3dcd4e7b44a06a0b5564c21c5c7bd","placeholder":"​","style":"IPY_MODEL_d6baa7d9ddce4c9a922049199c75e64c","value":"Filter: 100%"}},"640c9401a2b54ad2bd90c0638fd15f5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f7209a4d1594abfba4feb234bc08976","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4130671e2ac499382d9f0b3decaac19","value":100}},"1693a163c26f4bfd986acbf96b86c527":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5e6fc2d2fc84cbb9c6fa962f4deb28f","placeholder":"​","style":"IPY_MODEL_75d5d2d8295b4f3a9d968162166a5f08","value":" 100/100 [00:00&lt;00:00, 531.49 examples/s]"}},"bc3860755fb848399ceeab6523f25628":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0b3dcd4e7b44a06a0b5564c21c5c7bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6baa7d9ddce4c9a922049199c75e64c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f7209a4d1594abfba4feb234bc08976":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4130671e2ac499382d9f0b3decaac19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5e6fc2d2fc84cbb9c6fa962f4deb28f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75d5d2d8295b4f3a9d968162166a5f08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e31d31a282c0411bb543ec1a2fe96ae9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d74f33165ecb4f99a3910f4d494965b4","IPY_MODEL_871cab198e5a4a3e95b93aafa02eb8ff","IPY_MODEL_6b258c46d72045bcad669f50877209d5"],"layout":"IPY_MODEL_aa1dbc0fcdf343fc88f7be4c9632d9d1"}},"d74f33165ecb4f99a3910f4d494965b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85129c324b0e43208bd708420272776d","placeholder":"​","style":"IPY_MODEL_57b85ff0fd9344bebb4facec4a2911fd","value":"Filter: 100%"}},"871cab198e5a4a3e95b93aafa02eb8ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bd491c4fa6c4613bae21a8fad12ad3c","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4975df96fb684848bf82778f73037dae","value":100}},"6b258c46d72045bcad669f50877209d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1e6cbd0aad94ade9bed89de0222e78a","placeholder":"​","style":"IPY_MODEL_af0f429f7b7648ec89e5f0555ca17dfa","value":" 100/100 [00:00&lt;00:00, 529.65 examples/s]"}},"aa1dbc0fcdf343fc88f7be4c9632d9d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85129c324b0e43208bd708420272776d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57b85ff0fd9344bebb4facec4a2911fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bd491c4fa6c4613bae21a8fad12ad3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4975df96fb684848bf82778f73037dae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1e6cbd0aad94ade9bed89de0222e78a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af0f429f7b7648ec89e5f0555ca17dfa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_uXkvMPNq2Z","executionInfo":{"status":"ok","timestamp":1753558048068,"user_tz":-330,"elapsed":7129,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}},"outputId":"8997f206-a99f-41d0-a3d6-758d41a0ec08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting loguru\n","  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n","Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: loguru\n","Successfully installed loguru-0.7.3\n"]}],"source":["# !git clone https://github.com/EXL-Health-AI-Research/MEDIQA-OE-2025.git\n","\n","!pip install loguru\n","\n"]},{"cell_type":"code","source":["import os\n","import json\n","from pprint import pprint\n","from IPython.display import Markdown\n","import numpy as np\n","import pandas as pd\n","import torch\n","from datasets import Dataset, load_dataset\n","from typing import Optional, Union, Dict, Iterator, List, Literal\n","from abc import ABC, abstractmethod\n","import requests\n","from loguru import logger\n","from openai import OpenAI\n","from transformers import AutoModelForCausalLM, AutoProcessor, AutoTokenizer"],"metadata":{"id":"bK0e9x17rdOg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class MedicalOrderDataLoader:\n","#     def __init__(self, trs_json_path: str):\n","#         if not os.path.exists(trs_json_path):\n","#             raise FileNotFoundError(f\"Dataset file not found: {trs_json_path}\")\n","\n","#         self._validate_json_structure(trs_json_path)\n","\n","#         # Load the dataset from the local JSON file\n","#         dataset_dict = load_dataset(\"json\", data_files=trs_json_path)\n","\n","#         # Access the splits from the loaded dataset dictionary\n","#         self.ds = dataset_dict[\"train\"]\n","#         self.ds_val = dataset_dict[\"dev\"]\n","\n","\n","#     def _validate_json_structure(self, trs_json_path: str) -> None:\n","#         with open(trs_json_path, \"r\") as f:\n","#             data = json.load(f)\n","\n","#         if not isinstance(data, dict):\n","#             raise ValueError(\"JSON root should be a dictionary\")\n","\n","#         required_fields = ['train', 'dev']\n","#         for field in required_fields:\n","#             if field not in data:\n","#                 raise ValueError(f\"Missing required field: {field}\")\n","\n","#         for split_name, split_data in data.items():\n","#             if not isinstance(split_data, list):\n","#                 raise ValueError(f\"Split '{split_name}' should be a list, got {type(split_data)}\")\n","\n","#     def get_pandas(self) -> Union[Optional[pd.DataFrame], Optional[pd.DataFrame]]:\n","#         if isinstance(self.ds, Dataset) and isinstance(self.ds_val, Dataset):\n","#             return self.ds.to_pandas(), self.ds_val.to_pandas() # type: ignore"],"metadata":{"id":"EFlJoWoush-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"56e4747e"},"source":["class MedicalOrderDataLoader:\n","    def __init__(self, trs_json_path: str):\n","        if not os.path.exists(trs_json_path):\n","            raise FileNotFoundError(f\"Dataset file not found: {trs_json_path}\")\n","\n","        with open(trs_json_path, \"r\") as f:\n","            data = json.load(f)\n","\n","        if not isinstance(data, dict):\n","            raise ValueError(\"JSON root should be a dictionary\")\n","\n","        required_fields = ['train', 'dev']\n","        # required_fields = ['test']\n","        for field in required_fields:\n","            if field not in data:\n","                raise ValueError(f\"Missing required field: {field}\")\n","            if not isinstance(data[field], list):\n","                raise ValueError(f\"Split '{field}' should be a list, got {type(data[field])}\")\n","\n","        # Create Dataset objects from the loaded lists\n","        self.ds = Dataset.from_list(data[\"train\"])\n","        self.ds_val = Dataset.from_list(data[\"dev\"])\n","        # self.ds = Dataset.from_list(data[\"test\"])\n","\n","    def get_pandas(self) -> Union[Optional[pd.DataFrame], Optional[pd.DataFrame]]:\n","        if isinstance(self.ds, Dataset) and isinstance(self.ds_val, Dataset):\n","            return self.ds.to_pandas(), self.ds_val.to_pandas() # type: ignore\n","        return None, None # Return None if datasets are not loaded"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BaseOrderExtractionLM(ABC):\n","    @abstractmethod\n","    def infer(self, messages: List, max_new_tokens: int = 2048) -> str | None:\n","        pass\n","\n","    def get_device_info(self) -> str:\n","        return \"N/A\"\n","\n","    def token_count(self, messages: List) -> int:\n","        raise NotImplementedError(\"Token counting not supported for this backend.\")\n","\n","    def infer_stream(self, messages: List, max_new_tokens: int = 2048) -> Iterator[str]:\n","        raise NotImplementedError(\"Streaming not supported for this backend.\")"],"metadata":{"id":"nvGvUdtDtj-5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LocalOrderExtractorLM(BaseOrderExtractionLM):\n","    def __init__(self, model_name_or_path: str, device_map=None, load_processor=False):\n","        dtype = (\n","            torch.bfloat16\n","            if torch.cuda.get_device_capability()[0] >= 8\n","            else torch.float16\n","        )\n","        logger.info(f\"Loading local model {model_name_or_path} with dtype {dtype}\")\n","\n","        self.model = AutoModelForCausalLM.from_pretrained(\n","            model_name_or_path, torch_dtype=dtype, device_map=device_map or \"auto\"\n","        )\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","\n","        self.processor = None\n","        if load_processor:\n","            try:\n","                self.processor = AutoProcessor.from_pretrained(model_name_or_path)\n","            except Exception as e:\n","                logger.warning(f\"Processor loading failed: {e}\")\n","\n","    def infer(self, messages: List, max_new_tokens: int = 2048) -> str:\n","        inputs = self.tokenizer.apply_chat_template(\n","            messages,\n","            add_generation_prompt=True,\n","            tokenize=True,\n","            return_dict=True,\n","            return_tensors=\"pt\",\n","        ).to(self.model.device)\n","\n","        input_len = inputs[\"input_ids\"].shape[-1]\n","\n","        with torch.inference_mode():\n","            output = self.model.generate(\n","                **inputs,\n","                do_sample=False,\n","                temperature=0.1,\n","                max_new_tokens=max_new_tokens,\n","            )\n","            generated = output[0][input_len:]\n","\n","        return self.tokenizer.decode(generated, skip_special_tokens=True)\n","\n","    def get_device_info(self):\n","        return str(self.model.device)\n","\n","    def token_count(self, messages: List) -> int:\n","        input_ids = self.tokenizer.apply_chat_template(\n","            messages,\n","            add_generation_prompt=True,\n","            tokenize=True,\n","            return_tensors=\"pt\",\n","        )[\"input_ids\"]\n","        return input_ids.shape[-1]\n","\n","\n","class HostedOrderExtractionLM(BaseOrderExtractionLM):\n","    def __init__(self, model_name: str, api_base: str, api_key: str):\n","        self.model_name = model_name\n","        self.client = OpenAI(base_url=api_base, api_key=api_key)\n","\n","    def infer(self, messages: List, max_new_tokens: int = 2048) -> str | None:\n","        response = self.client.chat.completions.create(\n","            model=self.model_name,\n","            messages=messages,\n","            temperature=0.1,\n","            max_tokens=max_new_tokens,\n","        )\n","        return response.choices[0].message.content\n","\n","    def infer_stream(self, messages: List, max_new_tokens: int = 2048) -> Iterator[str]:\n","        stream = self.client.chat.completions.create(\n","            model=self.model_name,\n","            messages=messages,\n","            temperature=0.1,\n","            max_tokens=max_new_tokens,\n","            stream=True,\n","        )\n","        for chunk in stream:\n","            if chunk.choices[0].delta.content:\n","                yield chunk.choices[0].delta.content\n","\n","    def get_device_info(self):\n","        return f\"Remote: {self.client.base_url}\"\n","\n","    def token_count(self, messages: List) -> int:\n","        return self._tokenize(messages)\n","\n","    def _tokenize(self, prompt: List) -> int:\n","        # Assuming vLLM\n","        url = f\"{str(self.client.base_url).replace('/v1', '')}/tokenize\"\n","        headers = {\"Authorization\": f\"Bearer {self.client.api_key}\"}\n","        data = {\"model\": self.model_name, \"prompt\": prompt}\n","        resp = requests.post(url, json=data, headers=headers)\n","        if resp.status_code != 200:\n","            raise RuntimeError(f\"Tokenization failed: {resp.text}\")\n","\n","        return resp.json()[\"count\"]\n","\n","\n","class OrderExtractionLM:\n","    def __init__(\n","        self,\n","        backend: Literal[\"local\", \"openai\"],\n","        model_name_or_path: str,\n","        **kwargs,\n","    ):\n","        if backend == \"local\":\n","            self.impl = LocalOrderExtractorLM(model_name_or_path, **kwargs)\n","        elif backend == \"openai\":\n","            self.impl = HostedOrderExtractionLM(model_name_or_path, **kwargs)\n","        else:\n","            raise ValueError(f\"Unsupported backend: {backend}\")\n","\n","    def infer(self, messages: List, max_new_tokens: int = 2048):\n","        return self.impl.infer(messages, max_new_tokens)\n","\n","    def infer_stream(self, messages: List, max_new_tokens: int = 2048) -> Iterator[str]:\n","        return self.impl.infer_stream(messages, max_new_tokens)\n","\n","    def get_device_info(self):\n","        return self.impl.get_device_info()\n","\n","    def token_count(self, messages: List):\n","        return self.impl.token_count(messages)\n"],"metadata":{"id":"70ddBGDhtYW2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_loader = MedicalOrderDataLoader(trs_json_path=\"/content/orders_data_transcript.json\")\n","\n","\n","ds,ds_val = data_loader.ds, data_loader.ds_val\n","# ds = data_loader.ds"],"metadata":{"id":"JpYNuDdaudi0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds_val"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ukCpgQimuwlw","executionInfo":{"status":"ok","timestamp":1753558300424,"user_tz":-330,"elapsed":10,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}},"outputId":"a6325f89-bb5f-484e-84d5-8fe079d3fd4d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['id', 'expected_orders', 'transcript'],\n","    num_rows: 100\n","})"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# OPENAI_API_BASE = \"https://tasks-vessels-advantages-broadway.trycloudflare.com/v1\" # Note the /v1 at the end\n","# OPENAI_API_KEY = \"sk-IrR7Bwxtin0haWagUnPrSri5PurnUz86\" # Make sure to replace with the right one\n","# OPENAI_API_BASE=\"https://ib69u5a95i9zvw-8000.proxy.runpod.net/v1\"\n","# OPENAI_API_KEY=\"sk-c395fbc853ccdf090320d2a16b88e092\"\n","# OPENAI_API_BASE = 'https://lb9bckyr171rj7-8000.proxy.runpod.net/v1'\n","OPENAI_API_BASE = 'https://doug-endorsed-priced-comparing.trycloudflare.com/v1'\n","OPENAI_API_KEY = 'sk-IrR7Bwxtin0haWagUnPrSri5PurnUz86'\n"],"metadata":{"id":"MVcHYUkNyVeO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lm = OrderExtractionLM(\n","    backend=\"openai\",\n","    model_name_or_path=\"\",\n","    api_base=OPENAI_API_BASE,\n","    api_key=OPENAI_API_KEY\n",")"],"metadata":{"id":"E8U2NsUdyJ7g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print([model.id for model in lm.impl.client.models.list().data])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53p5vUO-ydms","executionInfo":{"status":"ok","timestamp":1753558305561,"user_tz":-330,"elapsed":1103,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}},"outputId":"c2aefa82-5fb8-4c8e-cef7-e4d4c30a01a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['google/medgemma-4b-it']\n"]}]},{"cell_type":"code","source":["test_msg = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": \"You are a medical AI assistant how answers in one sentence.\",\n","    },\n","    {\n","        \"role\": \"user\",\n","        \"content\": \"Hi, what kind of assistant are you?\",\n","    },\n","]\n","\n","out = lm.infer(\n","    messages=test_msg\n",")\n","\n","Markdown(out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":46},"id":"OAamW_X8yoNe","executionInfo":{"status":"ok","timestamp":1753558308914,"user_tz":-330,"elapsed":1017,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}},"outputId":"439f5006-05b0-4980-b974-6881cdad3706"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"I am a medical AI assistant designed to provide information and support related to health and medicine.\n"},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# sample"],"metadata":{"id":"f4Hqvl0WNAC1"}},{"cell_type":"code","source":["# # Robust Medical Order Classification Prompt\n","\n","#                         You are a medical expert classifying orders into types based on clinical intent and medical practice patterns.\n","\n","#                         ## 📋 CLASSIFICATION CATEGORIES\n","\n","#                         ### 1. *medication* - Drug-related orders\n","#                         - Prescriptions, dosages, pharmacy instructions\n","#                         - Starting, stopping, or changing medications\n","#                         - Injections, inhalers, topical treatments\n","#                         - Medication administration instructions\n","\n","#                         ### 2. *lab* - Laboratory and diagnostic testing\n","#                         - Blood tests, urinalysis, cultures\n","#                         - Screening tests, panels, titers\n","#                         - Diagnostic examinations requiring sample collection\n","#                         - Point-of-care testing\n","\n","#                         ### 3. *imaging* - Radiological and imaging studies\n","#                         - X-rays, CT scans, MRI, ultrasounds\n","#                         - Echocardiograms, mammograms\n","#                         - Any visual diagnostic study requiring imaging equipment\n","#                         - Radiological procedures\n","\n","#                         ### 4. *followup* - Appointments and care continuity\n","#                         - Return visits, follow-up appointments\n","#                         - Scheduling future care\n","#                         - Care coordination instructions\n","\n","#                         ## 🎯 CLASSIFICATION RULES\n","\n","#                         - *Use clinical intent*, not just keywords\n","#                         - *Each order gets exactly one type*\n","#                         - *Maintain original description and reason text*\n","#                         - *Consider medical context and purpose*\n","\n","#                         ## 📝 EXTENSIVE CLASSIFICATION EXAMPLES\n","\n","#                         ### ✅ *MEDICATION* Examples:\n","\n","#                         \"lasix 40 milligrams a day\"\n","#                         \"stop advil\"\n","#                         \"prednisone forty milligrams one tablet a day five days\"\n","#                         \"increase the lisinopril 40 milligrams once a day\"\n","#                         \"albuterol inhaler two puffs every four hours as needed\"\n","#                         \"nitroglycerin pill underneath your tongue up to three every five minutes\"\n","#                         \"daily baby aspirin eighty one milligrams once a day\"\n","#                         \"antihistamine\"\n","#                         \"steroid creams\"\n","#                         \"insulin\"\n","#                         \"tramadol 50 milligrams every six hours as needed\"\n","#                         \"metformin 1000 mg twice a day\"\n","#                         \"ibuprofen 600 milligrams four times a day with food\"\n","#                         \"cortisone injection\"\n","#                         \"hold off norvasc\"\n","#                         \"antibiotics\"\n","#                         \"emollients three four times a day for the next couple of week\"\n","\n","\n","#                         ### ✅ *LAB* Examples:\n","\n","#                         \"blood tests\"\n","#                         \"a1c\"\n","#                         \"lipid panel\"\n","#                         \"urinalysis urine\"\n","#                         \"urine culture\"\n","#                         \"complete metabolic panel\"\n","#                         \"psa blood\"\n","#                         \"blood cholesterol panel\"\n","#                         \"thyroid panel\"\n","#                         \"autoimmune panel\"\n","#                         \"pregnancy test\"\n","#                         \"covid test\"\n","#                         \"blood liver enzymes\"\n","#                         \"urine sample\"\n","#                         \"swab rapid strep test\"\n","#                         \"blood white blood cells two to three weeks\"\n","#                         \"western blot pcr\"\n","#                         \"cbc\"\n","#                         \"glucose test\"\n","#                         \"culture\"\n","\n","\n","#                         ### ✅ *IMAGING* Examples:\n","\n","#                         \"chest x-ray\n","#                         \"mri\"\n","#                         \"heart echocardiogram\"\n","#                         \"ultrasound\"\n","#                         \"mammogram\"\n","#                         \"cat scan of your chest chest\"\n","#                         \"lumbar spine mri\"\n","#                         \"echo in about two months\"\n","#                         \"pet ct ct\"\n","#                         \"imaging\"\n","#                         \"annual basis ultrasound\"\n","#                         \"echocardiogram\"\n","\n","\n","#                         ### ✅ *FOLLOWUP* Examples:\n","\n","#                         \"come back couple days\"\n","#                         \"follow-up in a week's time\"\n","#                         \"next two weeks follow up\"\n","#                         \"arrange a review in a week\"\n","#                         \"one month follow-up\"\n","#                         \"make an appointment\"\n","#                         \"book another appointment, to see you\"\n","#                         \"follow-up twenty four hours post procedur\"\n","#                         \"schedule an appointment four weeks\"\n","#                         \"after you get the blood tests after that's all done come in to see me\"\n","#                         \"followup six to nine months\"\n","#                         \"follow-up\"\n","#                         \"following up\"\n","\n","\n","#                         ## 🔍 CLASSIFICATION DECISION TREE\n","\n","#                         *Step 1: Identify Primary Action*\n","#                         - Is it prescribing/administering a substance? → *medication*\n","#                         - Is it collecting/testing a sample? → *lab*\n","#                         - Is it creating visual/diagnostic images? → *imaging*\n","#                         - Is it scheduling future care? → *followup*\n","\n","#                         *Step 2: Consider Clinical Context*\n","#                         - What is the healthcare provider's main intent?\n","#                         - What medical process is being initiated?\n","#                         - What outcome is expected?\n","\n","#                         *Step 3: Apply Medical Logic*\n","#                         - Would this typically be handled by pharmacy? → *medication*\n","#                         - Would this require lab technician? → *lab*\n","#                         - Would this need imaging equipment? → *imaging*\n","#                         - Would this involve appointment scheduling? → *followup*\n","\n","#                         ## ⚡ EDGE CASE GUIDELINES\n","\n","#                         *Complex Orders:*\n","#                         - \"mammogram in april of 2022 before you come back to see me\" → *imaging* (primary action is imaging)\n","#                         - \"blood tests after that's all done come in to see me\" → *lab* (primary action is testing)\n","#                         - \"after you get the blood tests after that's all done come in to see me or doctor ruth\" → *followup* (primary action is appointment)\n","\n","#                         *Medication vs Lab:*\n","#                         - \"insulin\" → *medication* (treatment)\n","#                         - \"glucose test\" → *lab* (testing)\n","\n","#                         *Imaging vs Lab:*\n","#                         - \"heart echocardiogram\" → *imaging* (visual study)\n","#                         - \"blood heart enzymes\" → *lab* (blood test)\n","\n","#                         ## 📤 OUTPUT FORMAT\n","\n","#                         Return a single valid JSON array:\n","\n","#                         json\n","#                         [\n","#                         {\n","#                             \"order_type\": \"medication\",\n","#                             \"description\": \"original description text\",\n","#                             \"reason\": \"original reason text\",\n","#                             \"provenance\": [turn_ids]\n","#                         },\n","#                         {\n","#                             \"order_type\": \"lab\",\n","#                             \"description\": \"original description text\",\n","#                             \"reason\": \"original reason text\",\n","#                             \"provenance\": [turn_ids]\n","#                         }\n","#                         ]\n","\n","\n","#                         ## 🎯 FINAL CLASSIFICATION CHECKLIST\n","\n","#                         Before finalizing classification:\n","#                         - [ ] Does the order_type match the primary clinical action?\n","#                         - [ ] Would a healthcare professional agree with this classification?\n","#                         - [ ] Is the classification based on intent, not just keywords?\n","#                         - [ ] Are all original text fields preserved exactly?\n","#                         - [ ] Is the JSON format valid and complete?\n","\n","#                         ## 📌 CRITICAL REMINDERS\n","\n","#                         - *One type per order* - No exceptions\n","#                         - *Preserve original text* - Never modify descriptions or reasons\n","#                         - *Clinical logic first* - Keywords are secondary\n","#                         - *Valid JSON only* - Return properly formatted array\n","#                         - *Context matters* - Consider the medical workflow implications\n","\n","#                         \"\"\""],"metadata":{"id":"KtFr-U3QoPQp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# prompt_2"],"metadata":{"id":"3sFHxhQvAJmu"}},{"cell_type":"code","source":["# SYSTEM_PROMPT = \"\"\"You are a medical AI assistant specialized in extracting medical orders from doctor-patient conversations.\n","\n","# Your task is to identify and extract all medical orders explicitly mentioned by the doctor, including:\n","# 1. Medications (prescriptions, dosage changes)\n","# 2. Laboratory tests\n","# 3. Imaging studies\n","# 4. Follow-up\n","\n","# For each order, extract the following:\n","# - order_type: \"medication\", \"lab\", \"imaging\", \"followup\"\n","# - description: Clear and specific, ideally under 20 words. If the description is long, split into multiple relevant orders.\n","# - reason: Medical condition or symptom being addressed. Keep this under 20 words as well.\n","# - provenance: Turn numbers where this order is mentioned\n","\n","# Always split overly long orders into multiple records for clarity and precision.\n","\n","# Return the results as a JSON list of objects.\"\"\"\n"],"metadata":{"id":"rTEB1lL7nPkC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# INSTRUCTION_TEMPLATE = \"\"\"Please extract all medical orders from the following doctor-patient conversation:\n","\n","# CONVERSATION:\n","# {conversation}\n","\n","# Extract all medical orders and return them as a JSON list with the following format:\n","# [\n","#   {{\n","#     \"order_type\": \"medication|lab|imaging|followup|referral\",\n","#     \"description\": \"specific description of the order (max 20 words)\",\n","#     \"reason\": \"short medical condition or reason for the order (max 20 words)\",\n","#     \"provenance\": [list of turn numbers where this order appears]\n","#   }}\n","# ]\n","\n","# Split long or compound orders into multiple clear entries. Be precise with medical terminology and avoid redundancy.\n","# \"\"\"\n"],"metadata":{"id":"1tqEO0aeopAq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SYSTEM_PROMPT = \"\"\"You are a medical AI assistant specializing in extracting **explicit medical orders** from structured doctor-patient conversations.\n","\n","# You will **reason step by step**, using the ReAct method:\n","# - First, read the conversation and identify any possible medical orders.\n","# - For each potential order, think aloud to explain:\n","#   - what the order is,\n","#   - what condition or symptom it is addressing,\n","#   - where in the transcript it was mentioned.\n","# - Then, act by returning the final output in strict JSON format, listing only clearly stated orders.\n","\n","# A valid medical order must:\n","# - Come from the DOCTOR.\n","# - Be clearly and explicitly stated.\n","# - Fall into one of these types:\n","#   - \"medication\"\n","#   - \"lab\"\n","#   - \"imaging\"\n","#   - \"followup\"\n","\n","# Each order should include:\n","# - \"order_type\": the category of order\n","# - \"description\": clear and specific text of the order\n","# - \"reason\": the medical reason or condition\n","# - \"provenance\": list of turn numbers where the order was mentioned\n","# \"\"\"\n","\n","# EXAMPLE_CONVERSATION = \"\"\"\n","# Turn 126 - DOCTOR: so, for your first problem of your shortness of breath i think that you are in an acute heart failure exacerbation.\n","# Turn 127 - DOCTOR: i want to go ahead and, uh, put you on some lasix, 40 milligrams a day.\n","# Turn 138 - DOCTOR: for your second problem of your type i diabetes, um, let's go ahead... i wanna order a hemoglobin a1c for, um, uh, just in a, like a month or so.\n","# \"\"\"\n","\n","# EXAMPLE_THINK_ACT = \"\"\"\n","# THOUGHT:\n","# - Turn 126 mentions \"shortness of breath\" and \"acute heart failure\".\n","# - Turn 127 includes an explicit medication order: \"lasix, 40 milligrams a day\".\n","# - Therefore, this is a medication order for heart failure.\n","\n","# - Turn 138 mentions \"type i diabetes\" and ordering a \"hemoglobin a1c\".\n","# - This is a clear lab test order to manage diabetes.\n","\n","# ACTION:\n","# [\n","#   {\n","#     \"order_type\": \"medication\",\n","#     \"description\": \"lasix 40 milligrams a day\",\n","#     \"reason\": \"shortness of breath acute heart failure exacerbation\",\n","#     \"provenance\": [126, 127]\n","#   },\n","#   {\n","#     \"order_type\": \"lab\",\n","#     \"description\": \"hemoglobin a1c\",\n","#     \"reason\": \"type i diabetes\",\n","#     \"provenance\": [138]\n","#   }\n","# ]\n","# \"\"\"\n","\n","# def build_prompt(conversation):\n","#     return f\"\"\"\n","# EXAMPLE CONVERSATION:\n","# {EXAMPLE_CONVERSATION}\n","\n","# EXAMPLE THINKING AND EXTRACTION:\n","# {EXAMPLE_THINK_ACT}\n","\n","# NOW APPLY THE SAME THINKING AND EXTRACTION TO THIS CONVERSATION:\n","\n","# {conversation}\n","\n","# Start with your THOUGHT, then give the ACTION as the final JSON output.\n","# \"\"\"\n","\n","# messages = [\n","#     {\n","#         \"role\": \"system\",\n","#         \"content\": SYSTEM_PROMPT,\n","#     },\n","#     {\n","#         \"role\": \"user\",\n","#         \"content\": build_prompt(conv),\n","#     }\n","# ]\n"],"metadata":{"id":"F4J9JmSSzOrE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# prompt 3"],"metadata":{"id":"U7Zkwd7MAcxo"}},{"cell_type":"code","source":["# 🔬 LAB EXAMPLES:\n","# - description: \"hemoglobin A1C\", reason: \"type i diabetes\"\n","# - description: \"urinalysis\", reason: \"difficulty urinating\"\n","# - description: \"lipid panel\", reason: \"coronary artery disease\"\n","# - description: \"cbc with differential\", reason: \"hyperlipidemia\"\n","# - description: \"urine culture\", reason: \"possible urinary tract infection\"\n","# - description: \"blood PSA\", reason: \"prostate cancer screening\"\n","# - description: \"autoimmune panel\", reason: \"lupus flare concern\"\n","\n","# 💊 MEDICATION EXAMPLES:\n","# - description: \"lasix 40 milligrams daily\", reason: \"shortness of breath from heart failure\"\n","# - description: \"metformin 500mg twice daily\", reason: \"type 2 diabetes\"\n","# - description: \"atorvastatin 20mg\", reason: \"high cholesterol\"\n","\n","# 🩻 IMAGING EXAMPLES:\n","# - description: \"chest x-ray\", reason: \"evaluate fluid in lungs\"\n","# - description: \"CT abdomen\", reason: \"abdominal pain\"\n","# - description: \"MRI lumbar spine\", reason: \"back pain\"\n","\n","# 📅 FOLLOW-UP EXAMPLES:\n","# - description: \"follow-up visit in 3 months\", reason: \"monitor blood pressure and cholesterol\"\n","# - description: \"cardiology referral\", reason: \"heart failure\"\n","# - description: \"endocrinology follow-up\", reason: \"diabetes management\""],"metadata":{"id":"JTTl1V-io1yB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SYSTEM_PROMPT = \"\"\"\n","# You are a clinical AI assistant extracting structured medical orders from doctor-patient conversations.\n","\n","# Your task is to extract all *explicit* medical orders suggested or prescribed by the doctor only. These include:\n","# 1. Medications\n","# 2. Laboratory tests\n","# 3. Imaging studies\n","# 4. Follow-up plans (including referrals)\n","\n","# For each order, extract:\n","# - order_type: One of \"medication\", \"lab\", \"imaging\", or \"followup\"\n","# - description: Clear and concise medical order (max 20 words). Normalize terms (e.g., \"a1c\" → \"hemoglobin A1C\").\n","# - reason: Clinical reason or medical condition (max 20 words)\n","# - provenance: List of turn numbers where the order is mentioned\n","\n","# Always split compound orders into multiple simple entries. Avoid vague entries like \"labs\" or \"testing\" unless context provides clarity.\n","\n","# Use these examples as guidance:\n","\n","# ## 📝 EXTENSIVE CLASSIFICATION EXAMPLES\n","\n","#       ### ✅ *MEDICATION* Examples:\n","\n","#       \"lasix 40 milligrams a day\"\n","#       \"stop advil\"\n","#       \"prednisone forty milligrams one tablet a day five days\"\n","#       \"increase the lisinopril 40 milligrams once a day\"\n","#       \"albuterol inhaler two puffs every four hours as needed\"\n","#       \"nitroglycerin pill underneath your tongue up to three every five minutes\"\n","#       \"daily baby aspirin eighty one milligrams once a day\"\n","#       \"antihistamine\"\n","#       \"steroid creams\"\n","#       \"insulin\"\n","#       \"tramadol 50 milligrams every six hours as needed\"\n","#       \"metformin 1000 mg twice a day\"\n","#       \"ibuprofen 600 milligrams four times a day with food\"\n","#       \"cortisone injection\"\n","#       \"hold off norvasc\"\n","#       \"antibiotics\"\n","#       \"emollients three four times a day for the next couple of week\"\n","\n","\n","#       ### ✅ *LAB* Examples:\n","\n","#       \"blood tests\"\n","#       \"a1c\"\n","#       \"lipid panel\"\n","#       \"urinalysis urine\"\n","#       \"urine culture\"\n","#       \"complete metabolic panel\"\n","#       \"psa blood\"\n","#       \"blood cholesterol panel\"\n","#       \"thyroid panel\"\n","#       \"autoimmune panel\"\n","#       \"pregnancy test\"\n","#       \"covid test\"\n","#       \"blood liver enzymes\"\n","#       \"urine sample\"\n","#       \"swab rapid strep test\"\n","#       \"blood white blood cells two to three weeks\"\n","#       \"western blot pcr\"\n","#       \"cbc\"\n","#       \"glucose test\"\n","#       \"culture\"\n","\n","#       ### ✅ *IMAGING* Examples:\n","\n","#       \"chest x-ray\n","#       \"mri\"\n","#       \"heart echocardiogram\"\n","#       \"ultrasound\"\n","#       \"mammogram\"\n","#       \"cat scan of your chest chest\"\n","#       \"lumbar spine mri\"\n","#       \"echo in about two months\"\n","#       \"pet ct ct\"\n","#       \"imaging\"\n","#       \"annual basis ultrasound\"\n","#       \"echocardiogram\"\n","\n","\n","#       ### ✅ *FOLLOWUP* Examples:\n","\n","#       \"come back couple days\"\n","#       \"follow-up in a week's time\"\n","#       \"next two weeks follow up\"\n","#       \"arrange a review in a week\"\n","#       \"one month follow-up\"\n","#       \"make an appointment\"\n","#       \"book another appointment, to see you\"\n","#       \"follow-up twenty four hours post procedur\"\n","#       \"schedule an appointment four weeks\"\n","#       \"after you get the blood tests after that's all done come in to see me\"\n","#       \"followup six to nine months\"\n","#       \"follow-up\"\n","#       \"following up\"\n","\n","\n","# Instructions:\n","# - includes order which are suggested by prescribed by doctor\n","# - Ignore vague statements like “we’ll keep checking” unless a clear order is given\n","# - Normalize spelling variations (e.g., \"a1c\", \"a1 c\", \"hemoglobin a1c\" → \"hemoglobin A1C\")\n","# - Avoid repeating identical tests unless the timing or reason is different\n","# - Return only structured JSON data\n","# - Don't include past history of patient medication, labs, or imaging\n","# \"\"\"\n"],"metadata":{"id":"LJ9VC217AfQn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SYSTEM_PROMPT = \"\"\"\n","You are a clinical AI assistant that extracts structured medical orders from doctor-patient conversations using ReAct (Reasoning and Acting) methodology.\n","\n","TASK: Extract ALL explicit medical orders that the doctor suggests, prescribes, or recommends during the conversation.\n","\n","CATEGORIES & EXAMPLES:\n","1. MEDICATION: \"lasix 40 milligrams daily\", \"stop advil\", \"prednisone 40mg once daily 5 days\", \"increase lisinopril 40mg once daily\", \"albuterol inhaler 2 puffs q4h prn\", \"daily baby aspirin 81mg\", \"hold norvasc\", \"antibiotics\", \"insulin\", \"tramadol 50mg q6h prn\"\n","\n","2. LAB: \"hemoglobin A1C\", \"lipid panel\", \"complete metabolic panel\", \"urinalysis\", \"urine culture\", \"PSA\", \"thyroid panel\", \"pregnancy test\", \"COVID test\", \"CBC\", \"glucose test\", \"blood culture\", \"Western blot PCR\"\n","\n","3. IMAGING: \"chest x-ray\", \"MRI\", \"echocardiogram\", \"ultrasound\", \"mammogram\", \"CT scan chest\", \"lumbar spine MRI\", \"PET CT\", \"annual ultrasound\"\n","\n","4. FOLLOWUP: \"follow-up in 1 week\", \"come back in 2 days\", \"schedule appointment in 4 weeks\", \"follow-up in 24 hours post-procedure\", \"follow-up 6-9 months\", \"make appointment\", \"arrange review in 1 week\"\n","\n","\n","EXTRACTION RULES:\n","- Only extract orders given BY THE DOCTOR (not patient history or past medications)\n","- Include explicit orders with clear clinical intent\n","- Split compound orders into separate entries\n","- Use EXACT words from the transcript - do not rephrase or normalize\n","- Include orders even if conditional (\"if symptoms persist, then...\")\n","- Focus on actionable, specific instructions\n","- Limit provenance to maximum 5 turn numbers\n","- Keep description and reason under 20 words each using exact transcript words\n","\n","AVOID:\n","- Vague statements without clear orders\n","- Patient's past medical history\n","- General discussions without specific instructions\n","- Repeated identical orders unless timing/reason differs\n","\n","EXTRACTION RULES FOR DESCRIPTION AND REASON:\n","1. DESCRIPTIONS: Only clear, clinically actionable medical orders related to:\n","- Medications (e.g., \"start metformin\", \"continue omeprazole 20 milligrams daily\")\n","- Lab tests (e.g., \"order a hemoglobin a1c\", \"check white blood cell count\")\n","- Imaging studies (e.g., \"schedule a chest x-ray\", \"get an MRI of the brain\")\n","- Follow-ups or Referrals (e.g., \"see endocrinologist\", \"come back in 2 weeks\")\n","2. REASONS: Only clinically meaningful problems, diagnoses, or symptoms that clearly explain why the above order is needed (e.g., \"for diabetes\", \"due to shortness of breath\")\n","\n","ReAct METHODOLOGY:\n","Use Chain of Thought (COT) reasoning with the following structure:\n","1. THOUGHT: Analyze the conversation to identify potential medical orders\n","2. ACTION: Extract specific orders with exact words from transcript\n","3. OBSERVATION: Verify extraction accuracy and completeness\n","4. FINAL OUTPUT: Return only the JSON array\n","\n","OUTPUT FORMAT:\n","- order_type: \"medication\", \"lab\", \"imaging\", or \"followup\"\n","- description: Extract exact words from transcript, max 20 words\n","- reason: Only clinically meaningful problems, diagnoses, or symptoms that clearly explain why the above order is needed (e.g., \"for diabetes\", \"due to shortness of breath\"), max 20 words\n","- provenance: Turn numbers where order appears, max 5 entries\n","\"\"\"\n","\n","INSTRUCTION_TEMPLATE = \"\"\"\n","Extract all medical orders from this doctor-patient conversation using ReAct methodology:\n","\n","CONVERSATION: {conversation}\n","\n","Follow this ReAct process:\n","\n","THOUGHT: Read through the conversation and identify all turns where the doctor gives explicit medical orders. Consider what type each order is (medication, lab, imaging, followup) and what the clinical reason is based on the conversation context.\n","\n","ACTION: For each identified order, extract the exact words from the transcript for both description and reason. Ensure each order has:\n","- Correct order_type classification\n","- Description using exact transcript words (max 20 words)\n","- Reason using exact transcript words (max 20 words)\n","- Provenance list with relevant turn numbers (max 5)\n","\n","OBSERVATION: Review the extracted orders to ensure:\n","- All explicit doctor orders are captured\n","- No patient history or past medications included\n","- Exact words used from transcript without paraphrasing\n","- Word limits respected (20 words max for description/reason)\n","- Provenance limited to 5 turn numbers maximum\n","- Compound orders are split into separate entries\n","\n","FINAL OUTPUT: Return ONLY the JSON array with no other text:\n","[\n","  {{\n","    \"order_type\": \"medication|lab|imaging|followup\",\n","    \"description\": \"exact words from transcript max 20 words\",\n","    \"reason\": \"exact words from transcript max 20 words\",\n","    \"provenance\": [max 5 turn numbers]\n","  }}\n","]\n","\n","CRITICAL: Output ONLY the JSON array after completing your reasoning. No explanations, no additional text, no formatting - just the JSON structure.\n","\"\"\"\n","\n","def format_messages(conv):\n","    instruction = INSTRUCTION_TEMPLATE.format(conversation=conv)\n","\n","    # ReAct example with Chain of Thought\n","    react_example = f\"\"\"\n","EXAMPLE CONVERSATION:\n","Turn 42 - DOCTOR: Your blood pressure is quite elevated today at 180/95.\n","Turn 43 - DOCTOR: I'm going to prescribe amlodipine 5mg once daily to help control this.\n","Turn 44 - DOCTOR: We should also check your kidney function with a creatinine level.\n","Turn 45 - DOCTOR: Please come back in 2 weeks so we can recheck your pressure.\n","\n","EXPECTED ReAct PROCESS:\n","\n","THOUGHT: I need to analyze this conversation for medical orders. I can see the doctor is addressing high blood pressure. In turn 43, there's a medication order for amlodipine. In turn 44, there's a lab order for creatinine. In turn 45, there's a follow-up appointment order. Each has a clear clinical reason mentioned in the conversation.\n","\n","ACTION: Extracting orders with exact words:\n","1. Medication order: \"amlodipine 5mg once daily\" for \"blood pressure is quite elevated\" (turns 42, 43)\n","2. Lab order: \"creatinine level\" to \"check your kidney function\" (turn 44)\n","3. Follow-up order: \"come back in 2 weeks\" to \"recheck your pressure\" (turn 45)\n","\n","OBSERVATION: I have identified 3 explicit medical orders from the doctor. All use exact words from the transcript. Word counts are within limits. Provenance is accurate and under 5 entries each. No patient history included.\n","\n","FINAL OUTPUT:\n","[\n","  {{\n","    \"order_type\": \"medication\",\n","    \"description\": \"amlodipine 5mg once daily\",\n","    \"reason\": \"blood pressure is quite elevated\",\n","    \"provenance\": [42, 43]\n","  }},\n","  {{\n","    \"order_type\": \"lab\",\n","    \"description\": \"creatinine level\",\n","    \"reason\": \"check your kidney function\",\n","    \"provenance\": [44]\n","  }},\n","  {{\n","    \"order_type\": \"followup\",\n","    \"description\": \"come back in 2 weeks\",\n","    \"reason\": \"recheck your pressure\",\n","    \"provenance\": [45]\n","  }}\n","]\n","\n","NOW EXTRACT FROM THIS CONVERSATION:\n","---\n","{instruction}\n","\"\"\"\n","\n","    messages = [\n","        {\n","            \"role\": \"system\",\n","            \"content\": SYSTEM_PROMPT,\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": instruction,\n","        }\n","    ]\n","\n","    return messages\n","\n","# Validation function for ReAct output\n","def validate_react_output(response):\n","    \"\"\"\n","    Validates that the ReAct response contains only JSON output\n","    \"\"\"\n","    try:\n","        # Find JSON array in response\n","        import json\n","        import re\n","\n","        # Look for JSON array pattern\n","        json_pattern = r'\\[.*\\]'\n","        matches = re.search(json_pattern, response, re.DOTALL)\n","\n","        if matches:\n","            json_str = matches.group(0)\n","            parsed = json.loads(json_str)\n","\n","            # Validate structure\n","            validated_orders = []\n","            for order in parsed:\n","                if all(key in order for key in ['order_type', 'description', 'reason', 'provenance']):\n","                    # Check constraints\n","                    if (order['order_type'] in ['medication', 'lab', 'imaging', 'followup'] and\n","                        len(order['description'].split()) <= 20 and\n","                        len(order['reason'].split()) <= 20 and\n","                        len(order['provenance']) <= 5):\n","                        validated_orders.append(order)\n","\n","            return validated_orders\n","\n","        return []\n","    except:\n","        return []"],"metadata":{"id":"e9xJT1KH9-Th"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SYSTEM_PROMPT = \"\"\"\n","# You are a clinical AI assistant that extracts structured medical orders from doctor-patient conversations.\n","\n","# TASK: Extract ALL explicit medical orders that the doctor suggests, prescribes, or recommends during the conversation.\n","\n","# CATEGORIES & EXAMPLES:\n","# 1. MEDICATION: \"lasix 40 milligrams daily\", \"stop advil\", \"prednisone 40mg once daily 5 days\", \"increase lisinopril 40mg once daily\", \"albuterol inhaler 2 puffs q4h prn\", \"daily baby aspirin 81mg\", \"hold norvasc\", \"antibiotics\", \"insulin\", \"tramadol 50mg q6h prn\"\n","\n","# 2. LAB: \"hemoglobin A1C\", \"lipid panel\", \"complete metabolic panel\", \"urinalysis\", \"urine culture\", \"PSA\", \"thyroid panel\", \"pregnancy test\", \"COVID test\", \"CBC\", \"glucose test\", \"blood culture\", \"Western blot PCR\"\n","\n","# 3. IMAGING: \"chest x-ray\", \"MRI\", \"echocardiogram\", \"ultrasound\", \"mammogram\", \"CT scan chest\", \"lumbar spine MRI\", \"PET CT\", \"annual ultrasound\"\n","\n","# 4. FOLLOWUP: \"follow-up in 1 week\", \"come back in 2 days\", \"schedule appointment in 4 weeks\", \"follow-up in 24 hours post-procedure\", \"follow-up 6-9 months\", \"make appointment\", \"arrange review in 1 week\"\n","\n","# EXTRACTION RULES:\n","# - Only extract orders given BY THE DOCTOR (not patient history or past medications)\n","# - Include explicit orders with clear clinical intent\n","# - Split compound orders into separate entries\n","# - Normalize medical terminology and abbreviations\n","# - Include orders even if conditional (\"if symptoms persist, then...\")\n","# - Focus on actionable, specific instructions\n","\n","# AVOID:\n","# - Vague statements without clear orders\n","# - Patient's past medical history\n","# - General discussions without specific instructions\n","# - Repeated identical orders unless timing/reason differs\n","\n","# OUTPUT FORMAT:\n","# Return ONLY the JSON array structure. No other text, explanations, or formatting.\n","# - order_type: \"medication\", \"lab\", \"imaging\", or \"followup\"\n","# - description: Normalized, concise order (focus on key medical terms)\n","# - reason: Primary clinical indication or condition\n","# - provenance: Turn numbers where order appears\n","# \"\"\"\n","\n","# INSTRUCTION_TEMPLATE = \"\"\"\n","# Extract all medical orders from this doctor-patient conversation:\n","\n","# CONVERSATION: {conversation}\n","\n","# Return ONLY a JSON array with this exact structure:\n","# [\n","#   {{\n","#     \"order_type\": \"medication|lab|imaging|followup\",\n","#     \"description\": \"clear medical order with key terms\",\n","#     \"reason\": \"clinical indication or condition\",\n","#     \"provenance\": [turn_numbers]\n","#   }}\n","# ]\n","\n","# CRITICAL: Output ONLY the JSON array. No explanations, no additional text, no formatting - just the JSON structure.\n","# \"\"\"\n","\n","# def format_messages(conv):\n","#     instruction = INSTRUCTION_TEMPLATE.format(conversation=conv)\n","\n","#     # Enhanced example that shows better provenance tracking and normalization\n","#     enhanced_example = f\"\"\"\n","# EXAMPLE CONVERSATION:\n","# Turn 126 - DOCTOR: For your shortness of breath, I think you're having an acute heart failure exacerbation.\n","# Turn 127 - DOCTOR: I want to start you on Lasix 40 milligrams daily for the fluid retention.\n","# Turn 138 - DOCTOR: For your diabetes, let's order an A1C.\n","\n","# EXPECTED OUTPUT:\n","# [\n","#   {{\n","#     \"order_type\": \"medication\",\n","#     \"description\": \"lasix 40 milligrams daily\",\n","#     \"reason\": \"acute heart failure exacerbation fluid retention\",\n","#     \"provenance\": [126, 127]\n","#   }},\n","#   {{\n","#     \"order_type\": \"lab\",\n","#     \"description\": \"hemoglobin A1C\",\n","#     \"reason\": \"diabetes\",\n","#     \"provenance\": [138]\n","#   }}\n","# ]\n","\n","# NOW EXTRACT FROM THIS CONVERSATION:\n","# ---\n","# {instruction}\n","# \"\"\"\n","\n","#     messages = [\n","#         {\n","#             \"role\": \"system\",\n","#             \"content\": SYSTEM_PROMPT,\n","#         },\n","#         {\n","#             \"role\": \"user\",\n","#             \"content\": instruction,\n","#         }\n","#     ]\n","\n","#     return messages\n","\n","# # Additional helper function for post-processing if needed\n","# def validate_extracted_orders(orders):\n","#     \"\"\"\n","#     Optional validation function to ensure extracted orders meet quality standards\n","#     \"\"\"\n","#     validated_orders = []\n","\n","#     for order in orders:\n","#         # Skip if missing required fields\n","#         if not all(key in order for key in ['order_type', 'description', 'reason', 'provenance']):\n","#             continue\n","\n","#         # Normalize order_type\n","#         if order['order_type'] not in ['medication', 'lab', 'imaging', 'followup']:\n","#             continue\n","\n","#         # Ensure provenance is a list\n","#         if not isinstance(order['provenance'], list):\n","#             continue\n","\n","#         # Basic length validation\n","#         if len(order['description']) > 100 or len(order['reason']) > 100:\n","#             continue\n","\n","#         validated_orders.append(order)\n","\n","#     return validated_orders"],"metadata":{"id":"DPTEyRuq2nWK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# INSTRUCTION_TEMPLATE = \"\"\"Please extract all medical orders from the following doctor-patient conversation:\n","\n","# CONVERSATION:\n","# {conversation}\n","\n","# Extract all explicit medical orders and return them as a JSON list using this format:\n","# [\n","#   {{\n","#     \"order_type\": \"medication|lab|imaging|followup\",\n","#     \"description\": \"clear and normalized order name (max 20 words)\",\n","#     \"reason\": \"brief clinical justification (max 20 words)\",\n","#     \"provenance\": [list of turn numbers where this order appears]\n","#   }}\n","# ]\n","\n","# Strictly follow these Rules:\n","# - Give the orders which are of suggestion or prescribed by the doctor\n","# - Don't want any orders which are past history medication, labs, or imaging\n","\n","# Rules:\n","# - Split compound instructions into separate orders\n","# - Normalize medical names and abbreviations\n","# - Drop vague or unclear instructions\n","# - Keep both `description` and `reason` concise\n","\n","\n","# Output only valid structured orders — no extra text.\n","# \"\"\"\n"],"metadata":{"id":"n0EtwUv-AfAG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# React prompt 2"],"metadata":{"id":"T4sFIYtKgx-H"}},{"cell_type":"code","source":["# SYSTEM_PROMPT = \"\"\"You are a medical AI assistant specialized in extracting medical orders from doctor-patient conversations using a ReAct (Reasoning and Acting) approach.\n","\n","# You will analyze conversations systematically by:\n","# 1. REASONING about what you observe in each turn\n","# 2. ACTING to identify and extract medical orders\n","# 3. REFLECTING on your findings to ensure completeness\n","\n","# Medical orders include:\n","# - Medications (prescriptions, dosage changes)\n","# - Laboratory tests\n","# - Imaging studies\n","# - Follow-up appointments\n","\n","# Use the following format for your analysis:\n","\n","# THOUGHT: [Your reasoning about what you're analyzing]\n","# ACTION: [What you're doing - scanning, identifying, extracting]\n","# OBSERVATION: [What you found in the current section]\n","# REFLECTION: [Whether you need to continue or if you found something important]\n","\n","# Continue this process until you've analyzed the entire conversation, then provide your final JSON output.\"\"\"\n","\n","# INSTRUCTION_TEMPLATE = \"\"\"Please extract all medical orders from the following doctor-patient conversation using the ReAct approach:\n","\n","# CONVERSATION:\n","# {conversation}\n","\n","# Follow this systematic process:\n","\n","# 1. SCAN: Read through the conversation and identify all doctor turns\n","# 2. ANALYZE: For each doctor turn, reason about potential medical orders\n","# 3. EXTRACT: Identify specific orders with their details\n","# 4. VALIDATE: Ensure all orders are captured with correct provenance\n","\n","# Use this format for your analysis:\n","\n","# THOUGHT: [What am I looking for in this turn?]\n","# ACTION: [Scanning turn X for medical orders]\n","# OBSERVATION: [What medical orders or relevant information did I find?]\n","# REFLECTION: [Is this a complete order? Do I need more context?]\n","\n","# After completing your analysis, provide the final JSON output:\n","\n","# [\n","#   {{\n","#     \"order_type\": \"medication|lab|imaging|followup\",\n","#     \"description\": \"specific description of the order\",\n","#     \"reason\": \"medical condition or reason for the order\",\n","#     \"provenance\": [list of turn numbers where this order appears]\n","#   }}\n","# ]\n","\n","# Remember to:\n","# - Focus only on explicit orders given by the doctor\n","# - Be precise with medical terminology\n","# - Track turn numbers accurately for provenance\n","# - Consider context from multiple turns for complete orders\"\"\"\n","\n","# def format_messages(conv):\n","#     instruction = INSTRUCTION_TEMPLATE.format(conversation=conv)\n","\n","#     example_section = \"\"\"\n","# EXAMPLE ANALYSIS:\n","\n","# CONVERSATION:\n","# Turn 126 - DOCTOR: so, for your first problem of your shortness of breath i think that you are in an acute heart failure exacerbation.\n","# Turn 127 - DOCTOR: i want to go ahead and, uh, put you on some lasix, 40 milligrams a day.\n","# Turn 138 - DOCTOR: for your second problem of your type i diabetes, um, let's go ahead... i wanna order a hemoglobin a1c for, um, uh, just in a month or so.\n","\n","# EXPECTED REACT ANALYSIS:\n","\n","# THOUGHT: I need to systematically analyze each doctor turn to identify medical orders.\n","# ACTION: Scanning turn 126 for medical orders\n","# OBSERVATION: Doctor is explaining diagnosis of acute heart failure exacerbation for shortness of breath. This is diagnostic reasoning, not an order yet.\n","# REFLECTION: This provides context but no direct order. Need to check next turns.\n","\n","# THOUGHT: Continuing to look for orders related to the heart failure diagnosis.\n","# ACTION: Scanning turn 127 for medical orders\n","# OBSERVATION: Doctor explicitly states \"i want to go ahead and, uh, put you on some lasix, 40 milligrams a day\" - this is a clear medication order.\n","# REFLECTION: Found complete medication order with dosage. Need to link to reason from turn 126.\n","\n","# THOUGHT: Moving to next section to look for additional orders.\n","# ACTION: Scanning turn 138 for medical orders\n","# OBSERVATION: Doctor says \"i wanna order a hemoglobin a1c\" - this is a laboratory test order for diabetes management.\n","# REFLECTION: Found complete lab order. Timeline mentioned is \"in a month or so\" but this is still an order.\n","\n","# FINAL EXTRACTION:\n","# [\n","#   {{\n","#     \"order_type\": \"medication\",\n","#     \"description\": \"lasix 40 milligrams a day\",\n","#     \"reason\": \"shortness of breath acute heart failure exacerbation\",\n","#     \"provenance\": [126, 127]\n","#   }},\n","#   {{\n","#     \"order_type\": \"lab\",\n","#     \"description\": \"hemoglobin a1c\",\n","#     \"reason\": \"type i diabetes\",\n","#     \"provenance\": [138]\n","#   }}\n","# ]\n","\n","# NOW ANALYZE THIS CONVERSATION:\n","# ---\n","# \"\"\"\n","\n","#     full_instruction = example_section + instruction\n","\n","#     messages = [\n","#         {\n","#             \"role\": \"system\",\n","#             \"content\": SYSTEM_PROMPT,\n","#         },\n","#         {\n","#             \"role\": \"user\",\n","#             \"content\": full_instruction,\n","#         }\n","#     ]\n","\n","#     return messages\n","\n","# # Alternative more structured ReAct approach\n","# def format_messages_structured(conv):\n","#     \"\"\"More structured ReAct approach with explicit action types\"\"\"\n","\n","#     structured_instruction = f\"\"\"\n","# Using the ReAct framework, analyze this doctor-patient conversation step by step:\n","\n","# CONVERSATION:\n","# {conv}\n","\n","# ANALYSIS FRAMEWORK:\n","# Use these specific action types in your reasoning:\n","\n","# ACTION_TYPES:\n","# - SCAN_TURN: Examine a specific conversation turn\n","# - IDENTIFY_ORDER: Recognize potential medical order language\n","# - EXTRACT_DETAILS: Pull out specific order information\n","# - LINK_CONTEXT: Connect orders to medical reasons from other turns\n","# - VALIDATE_ORDER: Confirm this is a complete, explicit order\n","\n","# REASONING PROCESS:\n","# For each turn, follow this pattern:\n","\n","# THOUGHT: [What am I analyzing and why?]\n","# ACTION: [SCAN_TURN/IDENTIFY_ORDER/EXTRACT_DETAILS/LINK_CONTEXT/VALIDATE_ORDER]\n","# OBSERVATION: [What did I find?]\n","# REFLECTION: [What does this mean for my extraction task?]\n","\n","# Continue until you've processed all turns, then provide your JSON output.\n","\n","# Focus on explicit doctor orders only. Be thorough but precise.\n","# \"\"\"\n","\n","#     messages = [\n","#         {\n","#             \"role\": \"system\",\n","#             \"content\": SYSTEM_PROMPT,\n","#         },\n","#         {\n","#             \"role\": \"user\",\n","#             \"content\": structured_instruction,\n","#         }\n","#     ]\n","\n","#     return messages"],"metadata":{"id":"0U2vELr-VgRj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# react prompt 2"],"metadata":{"id":"4NtS81Dug62B"}},{"cell_type":"code","source":["# SYSTEM_PROMPT = \"\"\"You are a medical AI assistant specialized in extracting medical orders from doctor-patient conversations.\n","\n","# Use systematic ReAct reasoning internally but output ONLY the final JSON result.\n","\n","# Medical orders include:\n","# - Medications (prescriptions, dosage changes, discontinuations)\n","# - Laboratory tests\n","# - Imaging studies\n","# - Follow-up appointments\n","\n","# Key Analysis Principles:\n","# 1. Orders may span multiple turns - link context across turns\n","# 2. Medical reasons may be mentioned earlier in the conversation\n","# 3. Timing/scheduling details should be included in descriptions\n","# 4. Some orders may have null reasons\n","# 5. Look for explicit ordering language: \"order\", \"get\", \"do\", \"check\", \"come back\"\n","\n","# Output ONLY valid JSON array. No reasoning shown.\"\"\"\n","\n","# INSTRUCTION_TEMPLATE = \"\"\"Extract medical orders from this conversation. Use systematic analysis to:\n","\n","# 1. IDENTIFY: Scan for ordering language and medical terms\n","# 2. CONTEXTUALIZE: Link orders to medical reasons from any turn\n","# 3. EXTRACT: Capture complete order details including timing\n","# 4. VALIDATE: Ensure provenance includes all relevant turns\n","\n","# CONVERSATION:\n","# {conversation}\n","\n","# Output format:\n","# [\n","#   {{\n","#     \"order_type\": \"medication|lab|imaging|followup|referral\",\n","#     \"description\": \"complete description including timing/details\",\n","#     \"reason\": \"medical condition/reason OR null if none\",\n","#     \"provenance\": [all relevant turn numbers]\n","#   }}\n","# ]\n","\n","# Return [] if no orders found.\"\"\"\n","\n","# def format_messages(conv):\n","#     instruction = INSTRUCTION_TEMPLATE.format(conversation=conv)\n","\n","#     examples = \"\"\"\n","# EXAMPLE 1 - MULTI-TURN CONTEXT LINKING:\n","\n","# CONVERSATION:\n","# Turn 8 - DOCTOR: she was febrile and had significantly elevated white blood cell count of 23,000.\n","# Turn 83 - DOCTOR: we could do some complete blood work including your white blood cells and a full panel of cholesterol, since it's been a while.\n","# Turn 86 - DOCTOR: if i put some labs in you could come in in two to three weeks?\n","\n","# OUTPUT:\n","# [\n","#   {\n","#     \"order_type\": \"lab\",\n","#     \"description\": \"blood white blood cells two to three weeks\",\n","#     \"reason\": \"significantly elevated white blood cell count of 23,000\",\n","#     \"provenance\": [8, 83, 86]\n","#   },\n","#   {\n","#     \"order_type\": \"lab\",\n","#     \"description\": \"blood panel of cholesterol two to three weeks\",\n","#     \"reason\": null,\n","#     \"provenance\": [83, 86]\n","#   }\n","# ]\n","\n","# EXAMPLE 2 - MEDICATION WITH TIMING:\n","\n","# CONVERSATION:\n","# Turn 15 - DOCTOR: Your blood pressure is concerning.\n","# Turn 16 - DOCTOR: Let's start you on lisinopril 10mg daily.\n","# Turn 17 - DOCTOR: Take it in the morning with food.\n","\n","# OUTPUT:\n","# [\n","#   {\n","#     \"order_type\": \"medication\",\n","#     \"description\": \"lisinopril 10mg daily in the morning with food\",\n","#     \"reason\": \"concerning blood pressure\",\n","#     \"provenance\": [15, 16, 17]\n","#   }\n","# ]\n","\n","# EXAMPLE 3 - IMAGING WITH SCHEDULING:\n","\n","# CONVERSATION:\n","# Turn 22 - DOCTOR: Given your chest pain history.\n","# Turn 23 - DOCTOR: I want to get a chest X-ray done.\n","# Turn 24 - DOCTOR: Can you do that this week?\n","\n","# OUTPUT:\n","# [\n","#   {\n","#     \"order_type\": \"imaging\",\n","#     \"description\": \"chest X-ray this week\",\n","#     \"reason\": \"chest pain history\",\n","#     \"provenance\": [22, 23, 24]\n","#   }\n","# ]\n","\n","# EXAMPLE 4 - FOLLOW-UP APPOINTMENT:\n","\n","# CONVERSATION:\n","# Turn 30 - DOCTOR: We need to monitor your diabetes control.\n","# Turn 31 - DOCTOR: Come back in 3 months.\n","# Turn 32 - DOCTOR: We'll check your A1C then.\n","\n","# OUTPUT:\n","# [\n","#   {\n","#     \"order_type\": \"followup\",\n","#     \"description\": \"follow-up appointment in 3 months to check A1C\",\n","#     \"reason\": \"monitor diabetes control\",\n","#     \"provenance\": [30, 31, 32]\n","#   }\n","# ]\n","\n","\n","\n","# EXAMPLE 5 - MEDICATION CHANGES:\n","\n","# CONVERSATION:\n","# Turn 60 - DOCTOR: Your current dose isn't controlling symptoms.\n","# Turn 61 - DOCTOR: Increase your metformin to 1000mg twice daily.\n","# Turn 62 - DOCTOR: Stop the glipizide completely.\n","\n","# OUTPUT:\n","# [\n","#   {\n","#     \"order_type\": \"medication\",\n","#     \"description\": \"increase metformin to 1000mg twice daily\",\n","#     \"reason\": \"current dose isn't controlling symptoms\",\n","#     \"provenance\": [60, 61]\n","#   },\n","#   {\n","#     \"order_type\": \"medication\",\n","#     \"description\": \"stop glipizide completely\",\n","#     \"reason\": \"current dose isn't controlling symptoms\",\n","#     \"provenance\": [60, 62]\n","#   }\n","# ]\n","\n","# NOW ANALYZE:\n","# ---\n","# \"\"\"\n","\n","#     full_instruction = examples + instruction\n","\n","#     messages = [\n","#         {\n","#             \"role\": \"system\",\n","#             \"content\": SYSTEM_PROMPT,\n","#         },\n","#         {\n","#             \"role\": \"user\",\n","#             \"content\": full_instruction,\n","#         }\n","#     ]\n","\n","#     return messages\n","\n","# # Alternative function for complex cases\n","# def format_messages(conv):\n","#     \"\"\"Enhanced version for complex multi-turn scenarios\"\"\"\n","\n","#     instruction = \"\"\"\n","# ADVANCED MEDICAL ORDER EXTRACTION\n","\n","# Apply these ReAct principles internally:\n","\n","# CONTEXT ANALYSIS:\n","# - Scan entire conversation for medical context before extracting orders\n","# - Medical reasons may appear many turns before the actual order\n","# - Orders may be confirmed/modified across multiple turns\n","\n","# PATTERN RECOGNITION:\n","\n","# MEDICATION ORDERS:\n","# - 'start', 'begin', 'initiate', 'prescribe', 'put on', 'add'\n","# - 'increase', 'decrease', 'adjust', 'titrate', 'reduce', 'up the dose'\n","# - 'switch to', 'change to', 'discontinue', 'stop', 'wean off'\n","# - 'twice daily', 'BID', 'TID', 'QID', 'PRN', 'as needed'\n","# - 'mg', 'units', 'tablets', 'capsules', 'ml', 'drops'\n","# - 'refill', 'continue', 'maintain current dose'\n","\n","# IMAGING ORDERS:\n","# - 'get a', 'order', 'schedule', 'need', 'obtain'\n","# - 'CT', 'MRI', 'X-ray', 'ultrasound', 'PET scan', 'DEXA'\n","# - 'with contrast', 'without contrast', 'bilateral', 'unilateral'\n","# - 'chest', 'abdomen', 'pelvis', 'brain', 'spine', 'extremity'\n","# - 'follow up imaging', 'repeat in', 'serial imaging'\n","\n","# LABORATORY ORDERS:\n","# - 'check', 'draw', 'get labs', 'blood work', 'urine', 'stool'\n","# - 'CBC', 'BMP', 'CMP', 'lipids', 'A1C', 'TSH', 'PSA'\n","# - 'fasting', 'random', 'trough level', 'peak level'\n","# - 'culture', 'sensitivity', 'biopsy', 'pathology'\n","# - 'in the morning', 'pre-op', 'post-op', 'baseline'\n","\n","# FOLLOW-UP ORDERS:\n","# - 'see you', 'come back', 'return', 'follow up', 'recheck'\n","# - 'in X weeks', 'next month', '3 months', 'annually'\n","# - 'sooner if', 'PRN', 'as needed', 'if symptoms worsen'\n","# - 'with me', 'with cardiology', 'with specialist'\n","# - 'bring results', 'after labs', 'post-procedure'\n","\n","# GENERAL ORDER INDICATORS:\n","# - 'could do', 'put in', 'order', 'get done', 'arrange'\n","# - 'let's', 'we should', 'I want', 'going to', 'plan to'\n","# - 'urgent', 'stat', 'emergent', 'routine', 'elective'\n","# - Timing phrases: 'today', 'tomorrow', 'this week', 'soon'\n","\n","# EXTRACTION STRATEGY:\n","# - Include ALL turns that contribute to the complete order\n","# - Merge timing details into descriptions\n","# - Link distant context when medically relevant\n","\n","# OUTPUT FORMAT REQUIREMENTS:\n","# - Use ONLY these 4 keys: order_type, description, reason, provenance\n","# - description: Complete order details including timing, dosage, specific procedures\n","# - reason: Medical justification (use null if routine/preventive)\n","# - provenance: Array of turn numbers that support this order\n","# - NO other fields allowed (no procedure_name, timing, details, etc.)\n","\n","\n","\n","\n","# Output only JSON array with exactly these 4 keys per order:\n","# [\n","#   {{\n","#     'order_type': 'string',\n","#     'description': 'complete order description with all details',\n","#     'reason': 'medical justification or null',\n","#     'provenance': [turn_numbers where order has been discussed]\n","#   }}\n","# ]\n","# CONVERSATION:\n","# \"\"\"\n","\n","#     messages = [\n","#         {\n","#             \"role\": \"system\",\n","#             \"content\": SYSTEM_PROMPT,\n","#         },\n","#         {\n","#             \"role\": \"user\",\n","#             \"content\": instruction+conv,\n","#         }\n","#     ]\n","\n","#     return messages"],"metadata":{"id":"LS3GHNeEg-Ma"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# model"],"metadata":{"id":"jIFR_oHYqRBS"}},{"cell_type":"code","source":["# SYSTEM_PROMPT = \"\"\"You are a medical AI assistant specialized in extracting medical orders from doctor-patient conversations.\n","\n","# Your task is to identify and extract all medical orders mentioned by the doctor, including:\n","# 1. Medications (prescriptions, dosage changes)\n","# 2. Laboratory tests\n","# 3. Imaging studies\n","# 4. Follow-up appointments\n","\n","# For each order, extract:\n","# - order_type: \"medication\", \"lab\", \"imaging\", \"followup\"\n","# - description: Clear description of what is being ordered\n","# - reason: Medical condition or symptom being addressed\n","# - provenance: Turn numbers where this order is mentioned\n","\n","# Return the results as a JSON list of objects.\"\"\"\n","\n","\n","# INSTRUCTION_TEMPLATE = \"\"\"Please extract all medical orders from the following doctor-patient conversation:\n","\n","# CONVERSATION:\n","# {conversation}\n","\n","# Extract all medical orders and return them as a JSON list with the following format:\n","# [\n","#   {{\n","#     \"order_type\": \"medication|lab|imaging|followup|referral\",\n","#     \"description\": \"specific description of the order\",\n","#     \"reason\": \"medical condition or reason for the order\",\n","#     \"provenance\": [list of turn numbers where this order appears]\n","#   }}\n","# ]\n","\n","# Focus on explicit orders given by the doctor. Be precise with medical terminology.\"\"\""],"metadata":{"id":"NlOkUt5-IEvS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SYSTEM_PROMPT = \"\"\"\n","# You are a medical AI assistant specialized in extracting EXPLICIT medical orders from doctor-patient conversations.\n","\n","# CRITICAL RULES:\n","# 1. Extract ONLY orders explicitly stated by the doctor\n","# 2. Do NOT infer or assume orders that aren't clearly mentioned\n","# 3. Provenance must be EXACT turn numbers where orders appear\n","# 4. Be balanced - i.e precision and recall on level terms\n","# 5. If the doctor orders multiple DISTINCT items (e.g., 'get a covid test and blood test'), create separate order objects for each item - never merge them into one combined description.\n","\n","# Order Types:\n","# - medication: Prescriptions, dosage instructions, medication changes\n","# - lab: Blood tests, urine tests, specific diagnostic tests\n","# - imaging: X-rays, MRI, CT scans, ultrasounds\n","# - followup: Scheduled return visits, check-ups (these must be explicitly stated by the doctor)\n","\n","# For each order extract:\n","# - order_type: One of the 4 types above\n","# - description: EXACT medical terminology used by doctor\n","# - reason: Specific condition/symptom mentioned by doctor\n","# - provenance: ONLY turn numbers where this exact order is mentioned\"\"\"\n","\n","\n","# INSTRUCTION_TEMPLATE = \"\"\"Please extract all medical orders from the following doctor-patient conversation:\n","\n","# CONVERSATION:\n","# {conversation}\n","\n","# Extract all medical orders and return them as a JSON list with the following format:\n","# [\n","#   {{\n","#     \"order_type\": \"medication|lab|imaging|followup|referral\",\n","#     \"description\": \"specific description of the order\",\n","#     \"reason\": \"medical condition or reason for the order\",\n","#     \"provenance\": [list of turn numbers where this order appears]\n","#   }}\n","# ]\n","\n","# Focus on explicit orders given by the doctor. Be precise with medical terminology.\"\"\""],"metadata":{"id":"9W73pAltw09l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def format_messages(conv):\n","#     instruction = INSTRUCTION_TEMPLATE.format(\n","#         conversation=conv,\n","#     )\n","#     instruction = f\"\"\"EXAMPLE CONVERSATION:\n","# Turn 126 - DOCTOR: so, for your first problem of your shortness of breath i think that you are in an acute heart failure exacerbation.\n","# Turn 127 - DOCTOR: i want to go ahead and, uh, put you on some lasix, 40 milligrams a day.\n","# Turn 138 - DOCTOR: for your second problem of your type i diabetes, um, let's go ahead... i wanna order a hemoglobin a1c for, um, uh, just in a, like a month or so.\n","\n","# EXPECTED OUTPUT:\n","# [\n","#   {{\n","#     \"order_type\": \"medication\",\n","#     \"description\": \"lasix 40 milligrams a day\",\n","#     \"reason\": \"shortness of breath acute heart failure exacerbation\",\n","#     \"provenance\": [126, 127]\n","#   }},\n","#   {{\n","#     \"order_type\": \"lab\",\n","#     \"description\": \"hemoglobin a1c\",\n","#     \"reason\": \"type i diabetes\",\n","#     \"provenance\": [138]\n","#   }}\n","# ]\n","\n","# NOW EXTRACT FROM THIS CONVERSATION:\n","\n","# ---\n","\n","# {instruction}\n","# \"\"\"\n","\n","#     messages = [\n","#         {\n","#             \"role\": \"system\",\n","#             \"content\": SYSTEM_PROMPT,\n","#         },\n","#         {\n","#             \"role\": \"user\",\n","#             \"content\": instruction,\n","#         }\n","#     ]\n","\n","#     return messages"],"metadata":{"id":"hd3xJ4KUu4Od"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# React prompt final"],"metadata":{"id":"OLNRRqUPMP1t"}},{"cell_type":"code","source":["SYSTEM_PROMPT = \"\"\"\n","You are a clinical AI assistant that extracts structured medical orders from doctor-patient conversations using ReAct (Reasoning and Acting) methodology.\n","\n","TASK: Extract ALL explicit medical orders that the doctor suggests, prescribes, or recommends during the conversation.\n","\n","CATEGORIES & EXAMPLES:\n","1. MEDICATION: \"lasix 40 milligrams daily\", \"stop advil\", \"prednisone 40mg once daily 5 days\", \"increase lisinopril 40mg once daily\", \"albuterol inhaler 2 puffs q4h prn\", \"daily baby aspirin 81mg\", \"hold norvasc\", \"antibiotics\", \"insulin\", \"tramadol 50mg q6h prn\"\n","\n","2. LAB: \"hemoglobin A1C\", \"lipid panel\", \"complete metabolic panel\", \"urinalysis\", \"urine culture\", \"PSA\", \"thyroid panel\", \"pregnancy test\", \"COVID test\", \"CBC\", \"glucose test\", \"blood culture\", \"Western blot PCR\"\n","\n","3. IMAGING: \"chest x-ray\", \"MRI\", \"echocardiogram\", \"ultrasound\", \"mammogram\", \"CT scan chest\", \"lumbar spine MRI\", \"PET CT\", \"annual ultrasound\"\n","\n","4. FOLLOWUP: \"follow-up in 1 week\", \"come back in 2 days\", \"schedule appointment in 4 weeks\", \"follow-up in 24 hours post-procedure\", \"follow-up 6-9 months\", \"make appointment\", \"arrange review in 1 week\"\n","\n","\n","EXTRACTION RULES:\n","- Only extract orders given BY THE DOCTOR (not patient history or past medications)\n","- Include explicit orders with clear clinical intent\n","- Split compound orders into separate entries\n","- Use EXACT words from the transcript - do not rephrase or normalize\n","- Include orders even if conditional (\"if symptoms persist, then...\")\n","- Focus on actionable, specific instructions\n","- Limit provenance to maximum 5 turn numbers\n","- Keep description and reason under 20 words each using exact transcript words\n","\n","AVOID:\n","- Vague statements without clear orders\n","- Patient's past medical history\n","- General discussions without specific instructions\n","- Repeated identical orders unless timing/reason differs\n","\n","EXTRACTION RULES FOR DESCRIPTION AND REASON:\n","1. DESCRIPTIONS: Only clear, clinically actionable medical orders related to:\n","- Medications (e.g., \"start metformin\", \"continue omeprazole 20 milligrams daily\")\n","- Lab tests (e.g., \"order a hemoglobin a1c\", \"check white blood cell count\")\n","- Imaging studies (e.g., \"schedule a chest x-ray\", \"get an MRI of the brain\")\n","- Follow-ups or Referrals (e.g., \"see endocrinologist\", \"come back in 2 weeks\")\n","2. REASONS: Only clinically meaningful problems, diagnoses, or symptoms that clearly explain why the above order is needed (e.g., \"for diabetes\", \"due to shortness of breath\")\n","\n","ReAct METHODOLOGY:\n","Use Chain of Thought (COT) reasoning with the following structure:\n","1. THOUGHT: Analyze the conversation to identify potential medical orders\n","2. ACTION: Extract specific orders with exact words from transcript\n","3. OBSERVATION: Verify extraction accuracy and completeness\n","4. FINAL OUTPUT: Return only the JSON array\n","\n","OUTPUT FORMAT:\n","- order_type: \"medication\", \"lab\", \"imaging\", or \"followup\"\n","- description: Extract exact words from transcript, max 20 words\n","- reason: Only clinically meaningful problems, diagnoses, or symptoms that clearly explain why the above order is needed (e.g., \"for diabetes\", \"due to shortness of breath\"), max 20 words\n","- provenance: Turn numbers where order appears, max 5 entries\n","\"\"\"\n","\n","INSTRUCTION_TEMPLATE = \"\"\"\n","Extract all medical orders from this doctor-patient conversation using ReAct methodology:\n","\n","CONVERSATION: {conversation}\n","\n","Follow this ReAct process:\n","\n","THOUGHT: Read through the conversation and identify all turns where the doctor gives explicit medical orders. Consider what type each order is (medication, lab, imaging, followup) and what the clinical reason is based on the conversation context.\n","\n","ACTION: For each identified order, extract the exact words from the transcript for both description and reason. Ensure each order has:\n","- Correct order_type classification\n","- Description using exact transcript words (max 20 words)\n","- Reason using exact transcript words (max 20 words)\n","- Provenance list with relevant turn numbers (max 5)\n","\n","OBSERVATION: Review the extracted orders to ensure:\n","- All explicit doctor orders are captured\n","- No patient history or past medications included\n","- Exact words used from transcript without paraphrasing\n","- Word limits respected (20 words max for description/reason)\n","- Provenance limited to 5 turn numbers maximum\n","- Compound orders are split into separate entries\n","\n","FINAL OUTPUT: Return ONLY the JSON array with no other text:\n","[\n","  {{\n","    \"order_type\": \"medication|lab|imaging|followup\",\n","    \"description\": \"exact words from transcript max 20 words\",\n","    \"reason\": \"exact words from transcript max 20 words\",\n","    \"provenance\": [max 5 turn numbers]\n","  }}\n","]\n","\n","CRITICAL: Output ONLY the JSON array after completing your reasoning. No explanations, no additional text, no formatting - just the JSON structure.\n","\"\"\""],"metadata":{"id":"ccBtbgV8MTSA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_messages(conv):\n","    instruction = INSTRUCTION_TEMPLATE.format(conversation=conv)\n","\n","    # ReAct example with Chain of Thought\n","    react_example = f\"\"\"\n","EXAMPLE CONVERSATION:\n","Turn 42 - DOCTOR: Your blood pressure is quite elevated today at 180/95.\n","Turn 43 - DOCTOR: I'm going to prescribe amlodipine 5mg once daily to help control this.\n","Turn 44 - DOCTOR: We should also check your kidney function with a creatinine level.\n","Turn 45 - DOCTOR: Please come back in 2 weeks so we can recheck your pressure.\n","\n","EXPECTED ReAct PROCESS:\n","\n","THOUGHT: I need to analyze this conversation for medical orders. I can see the doctor is addressing high blood pressure. In turn 43, there's a medication order for amlodipine. In turn 44, there's a lab order for creatinine. In turn 45, there's a follow-up appointment order. Each has a clear clinical reason mentioned in the conversation.\n","\n","ACTION: Extracting orders with exact words:\n","1. Medication order: \"amlodipine 5mg once daily\" for \"blood pressure is quite elevated\" (turns 42, 43)\n","2. Lab order: \"creatinine level\" to \"check your kidney function\" (turn 44)\n","3. Follow-up order: \"come back in 2 weeks\" to \"recheck your pressure\" (turn 45)\n","\n","OBSERVATION: I have identified 3 explicit medical orders from the doctor. All use exact words from the transcript. Word counts are within limits. Provenance is accurate and under 5 entries each. No patient history included.\n","\n","FINAL OUTPUT:\n","[\n","  {{\n","    \"order_type\": \"medication\",\n","    \"description\": \"amlodipine 5mg once daily\",\n","    \"reason\": \"blood pressure is quite elevated\",\n","    \"provenance\": [42, 43]\n","  }},\n","  {{\n","    \"order_type\": \"lab\",\n","    \"description\": \"creatinine level\",\n","    \"reason\": \"check your kidney function\",\n","    \"provenance\": [44]\n","  }},\n","  {{\n","    \"order_type\": \"followup\",\n","    \"description\": \"come back in 2 weeks\",\n","    \"reason\": \"recheck your pressure\",\n","    \"provenance\": [45]\n","  }}\n","]\n","\n","NOW EXTRACT FROM THIS CONVERSATION:\n","---\n","{instruction}\n","\"\"\"\n","\n","    messages = [\n","        {\n","            \"role\": \"system\",\n","            \"content\": SYSTEM_PROMPT,\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": instruction,\n","        }\n","    ]\n","\n","    return messages"],"metadata":{"id":"i8HORWOHMS6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _format_conv(turns, max_turns=-1, only_last_n=False):\n","    formatted = []\n","\n","    if max_turns > 0:\n","        turns = turns[-max_turns:] if only_last_n else turns[:max_turns]\n","\n","    for turn in turns:\n","        speaker = turn['speaker']\n","        text = turn['transcript']\n","        turn_id = turn['turn_id']\n","        formatted.append(f\"Turn {turn_id} - {speaker}: {text}\")\n","\n","    return \"\\n\".join(formatted)"],"metadata":{"id":"gVbiUn7Nytrk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def format_messages(conv):\n","#     example_conversation = \"\"\"Turn 126 - DOCTOR: so, for your first problem of your shortness of breath i think that you are in an acute heart failure exacerbation.\n","# Turn 127 - DOCTOR: i want to go ahead and, uh, put you on some lasix, 40 milligrams a day.\n","# Turn 138 - DOCTOR: for your second problem of your type i diabetes, um, let's go ahead... i wanna order a hemoglobin a1c for, um, uh, just in a, like a month or so.\"\"\"\n","\n","#     example_reasoning = \"\"\"THOUGHT:\n","# - Turn 126 describes shortness of breath and acute heart failure.\n","# - Turn 127 includes an explicit medication order: \"lasix, 40 milligrams a day\".\n","# - So this is a medication order addressing acute heart failure.\n","\n","# - Turn 138 references type I diabetes and ordering \"hemoglobin a1c\".\n","# - So this is a lab test order for diabetes monitoring.\n","\n","# ACTION:\n","# [\n","#   {\n","#     \"order_type\": \"medication\",\n","#     \"description\": \"lasix 40 milligrams a day\",\n","#     \"reason\": \"shortness of breath acute heart failure exacerbation\",\n","#     \"provenance\": [126, 127]\n","#   },\n","#   {\n","#     \"order_type\": \"lab\",\n","#     \"description\": \"hemoglobin a1c\",\n","#     \"reason\": \"type i diabetes\",\n","#     \"provenance\": [138]\n","#   }\n","# ]\"\"\"\n","\n","#     instruction = f\"\"\"\n","# EXAMPLE CONVERSATION:\n","# {example_conversation}\n","\n","# EXAMPLE THINKING AND EXTRACTION:\n","# {example_reasoning}\n","\n","# NOW APPLY THE SAME THINKING AND EXTRACTION TO THIS CONVERSATION:\n","\n","# {conv}\n","\n","# Start with your THOUGHT, then give the ACTION as the final JSON output.\n","# \"\"\"\n","\n","#     messages = [\n","#         {\n","#             \"role\": \"system\",\n","#             \"content\": SYSTEM_PROMPT,\n","#         },\n","#         {\n","#             \"role\": \"user\",\n","#             \"content\": instruction,\n","#         }\n","#     ]\n","#     return messages\n"],"metadata":{"id":"Ywv_PDBDzHFf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_data = ds[4]\n","\n","sample_conv = _format_conv(sample_data[\"transcript\"])\n","prompt = format_messages(conv=sample_conv)"],"metadata":{"id":"NVGJXMdN0E1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = \"\"\n","\n","for chunk in lm.infer_stream(prompt):\n","    response += chunk\n","    print(chunk, end=\"\", flush=True)\n"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"4AVwSL_b0OBX","executionInfo":{"status":"ok","timestamp":1753558336979,"user_tz":-330,"elapsed":9639,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}},"outputId":"429bffdc-7f9a-4482-e555-1e71c542fc42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["```json\n","[\n","  {\n","    \"order_type\": \"medication\",\n","    \"description\": \"meloxicam 15 mg once a day\",\n","    \"reason\": \"for back pain\",\n","    \"provenance\": [\n","      \"124\",\n","      \"125\",\n","      \"126\",\n","      \"127\",\n","      \"128\"\n","    ]\n","  },\n","  {\n","    \"order_type\": \"medication\",\n","    \"description\": \"increase metformin to 1000 mg twice a day\",\n","    \"reason\": \"for diabetes\",\n","    \"provenance\": [\n","      \"133\",\n","      \"134\",\n","      \"135\",\n","      \"136\",\n","      \"137\"\n","    ]\n","  },\n","  {\n","    \"order_type\": \"medication\",\n","    \"description\": \"order lisinopril 20 mg daily\",\n","    \"reason\": \"for hypertension\",\n","    \"provenance\": [\n","      \"140\",\n","      \"141\",\n","      \"142\",\n","      \"143\",\n","      \"147\"\n","    ]\n","  },\n","  {\n","    \"order_type\": \"followup\",\n","    \"description\": \"repeat a hemoglobin a1c in about 6 months\",\n","    \"reason\": \"for diabetes\",\n","    \"provenance\": [\n","      \"135\",\n","      \"136\",\n","      \"137\",\n","      \"138\",\n","      \"139\"\n","    ]\n","  },\n","  {\n","    \"order_type\": \"followup\",\n","    \"description\": \"refer you to physical therapy\",\n","    \"reason\": \"for back pain\",\n","    \"provenance\": [\n","      \"127\",\n","      \"128\",\n","      \"129\",\n","      \"130\",\n","      \"131\"\n","    ]\n","  }\n","]\n","```"]}]},{"cell_type":"code","source":["def infer_sample(sample, max_seqlen=8192):\n","    sample[\"pred\"] = None\n","    if not sample[\"transcript\"]:\n","        print(f\"Transcript is None, skipping...\")\n","        return sample\n","\n","    sample_conv = _format_conv(sample[\"transcript\"])\n","    prompt = format_messages(conv=sample_conv)\n","\n","    token_count = lm.token_count(prompt[-1]['content'])\n","    if token_count > 0.9 * max_seqlen:\n","        print(f\"Token length {token_count} exceeded max_seqlen {max_seqlen}, skipping...\")\n","        return sample\n","\n","    try:\n","        out = lm.infer(messages=prompt, max_new_tokens=2048)\n","        # print(out)\n","        sample[\"pred\"] = out\n","    except Exception as e:\n","        print(f\"Error in LLM call -> {e}\")\n","        return sample\n","\n","\n","    return sample"],"metadata":{"id":"WsQIYLU10O1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds_val = ds_val.map(infer_sample, num_proc=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["d66eedb40eae418fa06c631194e35f35","b0446a2b38ec4d5ca3b98b0e6f68021a","57fce6c42d954bf198e3652010a4ee17","9ab1537fc6b24e1aaebfcf67815a5a39","340d881dc42a4de684245dd761bc46d2","52b8d1db561e44789108b9ed39c310db","2eaf3ac5d8ff423f9c416808006bd91f","fae11f64f19b4b29a010f66b39fffb09","41c9922853cc48a893833f59fe4be898","eb0ddc83f6d34c878e7df8ac0987327e","c5bf48e8952642658fdbb71f3d1459d8"]},"id":"Ju6lGQif0jQV","executionInfo":{"status":"ok","timestamp":1753558923319,"user_tz":-330,"elapsed":580492,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}},"outputId":"e14a458f-1312-48b4-cfd3-455e7eb84970","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Parameter 'function'=<function infer_sample at 0x7b34f50ea840> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","WARNING:datasets.fingerprint:Parameter 'function'=<function infer_sample at 0x7b34f50ea840> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=3):   0%|          | 0/100 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d66eedb40eae418fa06c631194e35f35"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Error in LLM call -> Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 8128 tokens. However, you requested 8153 tokens (6105 in the messages, 2048 in the completion). Please reduce the length of the messages or completion. None\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n","Error in LLM call -> Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 8128 tokens. However, you requested 8283 tokens (6235 in the messages, 2048 in the completion). Please reduce the length of the messages or completion. None\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n","Error in LLM call -> Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 8128 tokens. However, you requested 8636 tokens (6588 in the messages, 2048 in the completion). Please reduce the length of the messages or completion. None\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n"]}]},{"cell_type":"code","source":["ds_val"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5BUvg8N0m4P","executionInfo":{"status":"ok","timestamp":1753559531528,"user_tz":-330,"elapsed":59,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}},"outputId":"312287f8-fe26-4aec-c029-e22819fef8e6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['id', 'expected_orders', 'transcript', 'pred'],\n","    num_rows: 100\n","})"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["ds_val.filter(lambda x: x[\"transcript\"] is None).num_rows, ds_val.filter(lambda x: x[\"pred\"] is None).num_rows"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98,"referenced_widgets":["d72a19f2e4824ceb9b8a338761c26e8b","7673cc7f6a614f7d9bdd22d918127e51","640c9401a2b54ad2bd90c0638fd15f5d","1693a163c26f4bfd986acbf96b86c527","bc3860755fb848399ceeab6523f25628","e0b3dcd4e7b44a06a0b5564c21c5c7bd","d6baa7d9ddce4c9a922049199c75e64c","9f7209a4d1594abfba4feb234bc08976","c4130671e2ac499382d9f0b3decaac19","e5e6fc2d2fc84cbb9c6fa962f4deb28f","75d5d2d8295b4f3a9d968162166a5f08","e31d31a282c0411bb543ec1a2fe96ae9","d74f33165ecb4f99a3910f4d494965b4","871cab198e5a4a3e95b93aafa02eb8ff","6b258c46d72045bcad669f50877209d5","aa1dbc0fcdf343fc88f7be4c9632d9d1","85129c324b0e43208bd708420272776d","57b85ff0fd9344bebb4facec4a2911fd","4bd491c4fa6c4613bae21a8fad12ad3c","4975df96fb684848bf82778f73037dae","b1e6cbd0aad94ade9bed89de0222e78a","af0f429f7b7648ec89e5f0555ca17dfa"]},"id":"hsBV2JgU1dX6","executionInfo":{"status":"ok","timestamp":1753559534474,"user_tz":-330,"elapsed":374,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}},"outputId":"a85f249e-2e04-4c24-ecb7-f71d92da1b57"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d72a19f2e4824ceb9b8a338761c26e8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e31d31a282c0411bb543ec1a2fe96ae9"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["(0, 3)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["pred = ds_val.to_pandas()"],"metadata":{"id":"NfiCkJ6D16dT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pred[['id', 'pred']]"],"metadata":{"id":"F3L-C3bB2Cvt","executionInfo":{"status":"ok","timestamp":1753563426485,"user_tz":-330,"elapsed":5,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","\n","# Assuming your DataFrame is named `df`\n","# and the column with the text is named 'notes_with_action'\n","count = 0\n","# Function to extract the ACTION JSON string using regex\n","def extract_action_json(text):\n","    # First try: triple-backtick JSON block\n","    if text:\n","      match_1 = re.search(r\"\\s*```json\\s*(.*?)\\s*```\", text, re.DOTALL)\n","      if match_1:\n","        return match_1.group(1)\n","      # If not found, fall back to raw JSON block\n","      if not match_1:\n","          match_2 = re.search(r\"\\s*```json\\s*(\\[.*)\",text, re.DOTALL)\n","      if match_2:\n","\n","        return match_2.group(1)\n","      # print()\n","      return None\n","    return None\n","\n","# (Optional) If you want to parse the JSON into Python objects (dicts/lists)\n","import json\n","import ast\n","\n","def parse_json(json_str):\n","    try:\n","        return json.loads(json_str)\n","    except:\n","        return ast.literal_eval(json_str)"],"metadata":{"collapsed":true,"id":"Gy-X-oHX2QoI","executionInfo":{"status":"ok","timestamp":1753563677014,"user_tz":-330,"elapsed":7,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["# Apply the function to create a new column\n","df[\"pred_json\"] = df[\"pred\"].apply(extract_action_json)"],"metadata":{"collapsed":true,"id":"mtgDW6sj3-SA","executionInfo":{"status":"ok","timestamp":1753563677837,"user_tz":-330,"elapsed":51,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["df[\"pred_json_parse\"] = df[\"pred_json\"].apply(parse_json)"],"metadata":{"id":"1KediETO5BC5","executionInfo":{"status":"error","timestamp":1753563678275,"user_tz":-330,"elapsed":40,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}},"colab":{"base_uri":"https://localhost:8080/","height":998},"outputId":"01136671-97d0-4830-c15d-1a3ed45e2611"},"execution_count":67,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"'{' was never closed (<unknown>, line 314)","traceback":["Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n","  File \u001b[1;32m\"/tmp/ipython-input-65-3282863877.py\"\u001b[0m, line \u001b[1;32m30\u001b[0m, in \u001b[1;35mparse_json\u001b[0m\n    return json.loads(json_str)\n","  File \u001b[1;32m\"/usr/lib/python3.11/json/__init__.py\"\u001b[0m, line \u001b[1;32m346\u001b[0m, in \u001b[1;35mloads\u001b[0m\n    return _default_decoder.decode(s)\n","  File \u001b[1;32m\"/usr/lib/python3.11/json/decoder.py\"\u001b[0m, line \u001b[1;32m337\u001b[0m, in \u001b[1;35mdecode\u001b[0m\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","\u001b[0;36m  File \u001b[0;32m\"/usr/lib/python3.11/json/decoder.py\"\u001b[0;36m, line \u001b[0;32m353\u001b[0;36m, in \u001b[0;35mraw_decode\u001b[0;36m\u001b[0m\n\u001b[0;31m    obj, end = self.scan_once(s, idx)\u001b[0m\n","\u001b[0;31mJSONDecodeError\u001b[0m\u001b[0;31m:\u001b[0m Expecting property name enclosed in double quotes\n","\nDuring handling of the above exception, another exception occurred:\n","Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n","  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \u001b[1;32m\"/tmp/ipython-input-67-3082496121.py\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<cell line: 0>\u001b[0m\n    df[\"pred_json_parse\"] = df[\"pred_json\"].apply(parse_json)\n","  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\"\u001b[0m, line \u001b[1;32m4924\u001b[0m, in \u001b[1;35mapply\u001b[0m\n    ).apply()\n","  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\"\u001b[0m, line \u001b[1;32m1427\u001b[0m, in \u001b[1;35mapply\u001b[0m\n    return self.apply_standard()\n","  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\"\u001b[0m, line \u001b[1;32m1507\u001b[0m, in \u001b[1;35mapply_standard\u001b[0m\n    mapped = obj._map_values(\n","  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\"\u001b[0m, line \u001b[1;32m921\u001b[0m, in \u001b[1;35m_map_values\u001b[0m\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n","  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\"\u001b[0m, line \u001b[1;32m1743\u001b[0m, in \u001b[1;35mmap_array\u001b[0m\n    return lib.map_infer(values, mapper, convert=convert)\n","  File \u001b[1;32m\"lib.pyx\"\u001b[0m, line \u001b[1;32m2972\u001b[0m, in \u001b[1;35mpandas._libs.lib.map_infer\u001b[0m\n","  File \u001b[1;32m\"/tmp/ipython-input-65-3282863877.py\"\u001b[0m, line \u001b[1;32m32\u001b[0m, in \u001b[1;35mparse_json\u001b[0m\n    return ast.literal_eval(json_str)\n","  File \u001b[1;32m\"/usr/lib/python3.11/ast.py\"\u001b[0m, line \u001b[1;32m64\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\n","\u001b[0;36m  File \u001b[0;32m\"/usr/lib/python3.11/ast.py\"\u001b[0;36m, line \u001b[0;32m50\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0m\n","\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m314\u001b[0m\n\u001b[0;31m    {\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '{' was never closed\n"]}]},{"cell_type":"code","source":["df.iloc[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"-rZ5H5w0c_5I","executionInfo":{"status":"ok","timestamp":1753563463464,"user_tz":-330,"elapsed":61,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}},"outputId":"72b1223f-86b2-4c15-9008-a2e7c1eeb399"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                       acibench_D2N182_virtscribe_clef_taskC_test3\n","pred               ```json\\n[\\n  {\\n    \"order_type\": \"medication...\n","pred_json          [\\n  {\\n    \"order_type\": \"medication\",\\n    \"...\n","pred_json_parse                                                 None\n","Name: 0, dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>id</th>\n","      <td>acibench_D2N182_virtscribe_clef_taskC_test3</td>\n","    </tr>\n","    <tr>\n","      <th>pred</th>\n","      <td>```json\\n[\\n  {\\n    \"order_type\": \"medication...</td>\n","    </tr>\n","    <tr>\n","      <th>pred_json</th>\n","      <td>[\\n  {\\n    \"order_type\": \"medication\",\\n    \"...</td>\n","    </tr>\n","    <tr>\n","      <th>pred_json_parse</th>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":[" df.to_excel('pred_medgemma_4b_prompt_1.xlsx')"],"metadata":{"id":"JbJlyl427Qqv","executionInfo":{"status":"ok","timestamp":1753561842138,"user_tz":-330,"elapsed":825,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["id_to_pred_dict = dict(zip(df['id'], df['pred_json_parse']))"],"metadata":{"id":"11gVRmeg1cqh","executionInfo":{"status":"ok","timestamp":1753562143235,"user_tz":-330,"elapsed":7,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jaf-IBnQG1OQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# If pred_json_parse column has strings that are valid Python lists, you may want to parse them:\n","import ast\n","\n","id_to_pred_dict = {\n","    row['id']: ast.literal_eval(row['pred_json_parse']) if isinstance(row['pred_json_parse'], str) else row['pred_json_parse']\n","    for _, row in df.iterrows()\n","}"],"metadata":{"id":"ntOIzZe97ZeT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('./pred_orders_react_4b_1.json','w')as f:\n","  json.dump(id_to_pred_dict,f,indent =2)"],"metadata":{"id":"Ig8fX75AAMNm","collapsed":true,"executionInfo":{"status":"ok","timestamp":1753562151262,"user_tz":-330,"elapsed":13,"user":{"displayName":"praveen bavana","userId":"06197844756715122954"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JbVB0Qgd1Rg5"},"execution_count":null,"outputs":[]}]}